{"metadata":{"kernelspec":{"name":"ir","display_name":"R","language":"R"},"language_info":{"name":"R","codemirror_mode":"r","pygments_lexer":"r","mimetype":"text/x-r-source","file_extension":".r","version":"4.0.5"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/havikhurana/dataset-reduction?scriptVersionId=113323752\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"raw","source":"This notebook contains the initial recipe processed on 50,000 images that reduced the columns from 8000 to about 1300.","metadata":{}},{"cell_type":"code","source":"library(recipes)","metadata":{"execution":{"iopub.status.busy":"2022-12-07T07:02:19.22699Z","iopub.execute_input":"2022-12-07T07:02:19.234042Z","iopub.status.idle":"2022-12-07T07:02:56.809801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#read and inspect the structure of the dataset\nimage <- read.csv(\"/kaggle/input/image-feature-extraction/image_feature.csv\") %>%\n    #rbind(read.csv(\"/kaggle/input/fp-image1/image_feature_8736.csv\")) %>%\n    select(-X)\n","metadata":{"_uuid":"051d70d956493feee0c6d64651c6a088724dca2a","_execution_state":"idle","execution":{"iopub.status.busy":"2022-12-07T07:02:56.812497Z","iopub.execute_input":"2022-12-07T07:02:56.836335Z","iopub.status.idle":"2022-12-07T07:03:41.208045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dim(image)\ncolnames(image)\nstr(image)","metadata":{"execution":{"iopub.status.busy":"2022-12-07T07:03:41.210973Z","iopub.execute_input":"2022-12-07T07:03:41.212211Z","iopub.status.idle":"2022-12-07T07:03:41.227242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we can see, there are 8000+ columns, I'll remove the columns with zero variance, near zero variance, and those that are highly correlated. Next, I'll see the columns that are preserved, and subset the dataset to those columns to stress on processor and RAM. I'll export the new subsetted dataset, and write a new recipe with only transformation steps.","metadata":{}},{"cell_type":"markdown","source":"**Step 1**\n\nFirst, split the test and training datasets, so that there is a subset the the code never sees. Then, use the training dataset to remove the columns.","metadata":{}},{"cell_type":"code","source":"test_train_split <- function(df, percent = 0.8){\n        set.seed(10312022)\n        rows <- sample(1:nrow(df), round(nrow(df)*percent))\n        train <- df[rows,]\n        test <- df[-rows,]\n        return(list(train, test))\n    }","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_split <- test_train_split(image)\nimage_train <- image_split[[1]]\nimage_test <- image_split[[2]]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dim(image_train)\ndim(image_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Create a recipe for the image dataset","metadata":{}},{"cell_type":"code","source":"blueprint_image_1 <- recipe(x  = image_train,\n                          vars  = colnames(image_train),\n                          roles = c('id', 'outcome',rep('predictor',ncol(image_train)-2))) %>%\n  # remove zero variance - no columns removed\n  step_zv(all_numeric_predictors()) %>%\n  # remove near zero variance - about half columns removed (4000)\n  step_nzv(all_numeric_predictors()) %>%\n  # remove highly correlated columns - about 2500 columns more removed\n  step_corr(all_numeric_predictors(), threshold = .5)","metadata":{"execution":{"iopub.status.busy":"2022-12-07T07:03:41.229411Z","iopub.execute_input":"2022-12-07T07:03:41.230387Z","iopub.status.idle":"2022-12-07T07:03:41.399927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"blueprint_image_1","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" prep <- prep(blueprint_image_1, \n                training = image_train)","metadata":{"execution":{"iopub.status.busy":"2022-12-07T07:03:41.402838Z","iopub.execute_input":"2022-12-07T07:03:41.404036Z","iopub.status.idle":"2022-12-07T07:08:38.514772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prep","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"keep_var <- prep %>% \n            summary %>% \n            select(variable) %>% \n            unlist()\n\nkeep_var <- unname(keep_var)\nkeep_var\nlength(keep_var)","metadata":{"execution":{"iopub.status.busy":"2022-12-07T07:08:38.516433Z","iopub.execute_input":"2022-12-07T07:08:38.517384Z","iopub.status.idle":"2022-12-07T07:08:38.529002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image1 <- image %>%\n        select(c(1,2,keep_var))","metadata":{"execution":{"iopub.status.busy":"2022-12-07T07:13:45.511422Z","iopub.execute_input":"2022-12-07T07:13:45.51322Z","iopub.status.idle":"2022-12-07T07:13:45.547797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dim(image1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#export this\nwrite.csv(image1, \n          \"/kaggle/working/subset_image_features.csv\",\n         row.names = TRUE)","metadata":{},"execution_count":null,"outputs":[]}]}